{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"npc_io","text":"<p>File IO tools for MindScope Neuropixels projects, compatible with data in the cloud.</p> <p> </p> <p> </p>"},{"location":"#usage","title":"Usage","text":"<pre><code>conda create -n npc_io python&gt;=3.9\nconda activate npc_io\npip install npc_io\n</code></pre> <pre><code>import npc_io\n</code></pre>"},{"location":"#development","title":"Development","text":"<p>See instructions in https://github.com/AllenInstitute/npc_io/CONTRIBUTING.md and the original template: https://github.com/AllenInstitute/copier-pdm-npc/blob/main/README.md</p>"},{"location":"changelog/","title":"Changelog","text":"<p>All notable changes to this project will be documented in this file.</p> <p>The format is based on Keep a Changelog and this project adheres to Semantic Versioning.</p>"},{"location":"changelog/#010-2024-02-01","title":"0.1.0 - 2024-02-01","text":"<p>Compare with first commit</p>"},{"location":"changelog/#added","title":"Added","text":"<ul> <li>Add comment on Python version cap (27bc626 by bjhardcastle).</li> <li>Add publish.yml explicitly to trigger workflow (aa9fac0 by bjhardcastle).</li> <li>Add path filter for publish workflow (066a1b9 by bjhardcastle).</li> <li>Add file_io.py from <code>npc_sessions</code> (1a2b6c1 by bjhardcastle).</li> <li>Add load_dotenv() function and testmod() function to init.py (638679a by bjhardcastle).</li> <li>Add s3fs dependency (b28d787 by bjhardcastle).</li> <li>Add dependencies (9f569ff by bjhardcastle).</li> </ul>"},{"location":"changelog/#fixed","title":"Fixed","text":"<ul> <li>Fix publishing (170a21a by bjhardcastle).</li> <li>Fix bump script (502c367 by bjhardcastle).</li> <li>Fix version syntax (b78187c by bjhardcastle).</li> <li>Fix python version &lt;3.12 (38f96bb by bjhardcastle).</li> <li>Fix docs.yml syntax (efb3496 by bjhardcastle).</li> <li>Fix yaml syntax (998e22c by bjhardcastle).</li> <li>Fix init (782b8be by bjhardcastle).</li> </ul>"},{"location":"contributing/","title":"Contributing","text":"<p>Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given.</p>"},{"location":"contributing/#environment-setup","title":"Environment setup","text":"<ol> <li> <p>Fork and clone the repository: <pre><code>git clone https://github.com/AllenInstitute/npc_io\ncd npc_io\n</code></pre></p> </li> <li> <p>Create a new virtual environment:</p> </li> <li>conda is convenient for getting a specific Python version, but adds additional packages</li> <li>it's preferable to use a completely clean environment to properly test the project's specified dependencies in isolation</li> <li> <p>where possible, use the lowest supported Python version (specified in <code>pyproject.toml</code> <code>project/requires-python</code>)  <pre><code>python3 -m venv .venv\n</code></pre></p> </li> <li> <p>Activate the environment:</p> </li> <li> <p>Windows   <pre><code>.venv\\scripts\\activate\n</code></pre></p> </li> <li> <p>Unix   <pre><code>source .venv/bin/scripts/activate\n</code></pre></p> </li> <li> <p>Add PDM to manage the project's dependencies and run pre-build jobs: <pre><code>pip install pdm\npdm install\n</code></pre></p> </li> </ol> <p>You now have an editable pip install of the project, with all dev dependencies. The following should work: <pre><code>python -c \"import npc_io; print(npc_io.__version__)\"\n</code></pre></p>"},{"location":"contributing/#using-pdm","title":"Using PDM","text":"<p>The project uses PDM for reproducible dev environments, with pre-defined <code>pyproject.toml</code> configuration for tools While working on the project, use PDM to manage dependencies: - add dependencies: <code>pdm add numpy pandas</code>   - add dev dependencies: <code>pdm add -G dev mypy</code> - remove dependencies correctly: <code>pdm remove numpy</code>   # does nothing because pandas still needs numpy! - update the environment to reflect changes in <code>pyproject.toml</code>: <code>pdm update</code> Always commit &amp; push <code>pdm.lock</code> to share the up-to-date dev environment</p>"},{"location":"contributing/#development-internal-contributors","title":"Development (internal contributors)","text":"<ol> <li> <p>Edit the code and/or the documentation on the main branch</p> </li> <li> <p>Add simple doctests to functions or more elaborate tests to modules in <code>tests</code></p> </li> <li> <p>If you updated the project's dependencies (or you pulled changes):</p> </li> <li>run <code>pdm update</code></li> <li>if it fails due to dependencies you added, follow any error messages to resolve dependency version conflicts</li> <li> <p>when it doesn't fail, commit any changes to <code>pdm.lock</code> along with the changes to <code>pyproject.toml</code></p> </li> <li> <p>Run tests with <code>pdm run test</code></p> </li> <li>mypy will check all functions that contain type annotations in their signature</li> <li> <p>pytest will run doctests and any tests in the <code>tests</code> dir</p> </li> <li> <p>If you updated the documentation or the project dependencies:</p> </li> <li>run <code>pdm run doc</code></li> <li> <p>go to http://localhost:8000 and check that everything looks good</p> </li> <li> <p>if you are unsure about how to fix a test, just push your changes - the continuous integration will fail on Github and someone else can have a look</p> </li> <li> <p>don't update the changelog, it will be taken care of automatically</p> </li> <li> <p>link to any related issue number in the Commit message: <code>Fix variable name #13</code> </p> </li> <li> <p>pull changes with <code>git pull --rebase</code> to keep the commit history easy to read</p> </li> </ol>"},{"location":"contributing/#updating-from-the-original-template","title":"Updating from the original template","text":"<p>With a clean working directory, run <code>pipx run copier update --defaults</code>.</p> <p>See here for more info.</p>"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li> npc_io<ul> <li> cached_property</li> <li> file_io</li> <li> lazy_dict</li> <li> types</li> </ul> </li> </ul>"},{"location":"reference/npc_io/","title":"Index","text":""},{"location":"reference/npc_io/#npc_io","title":"npc_io","text":"<p>File IO tools for MindScope Neuropixels projects, compatible with data in the cloud.</p>"},{"location":"reference/npc_io/#npc_io.load_dotenv","title":"load_dotenv","text":"<pre><code>load_dotenv() -&gt; None\n</code></pre> <p>Load environment variables from .env file in current working directory.</p> <p>load_dotenv()</p> Source code in <code>npc_io/__init__.py</code> <pre><code>def load_dotenv() -&gt; None:\n    \"\"\"\n    Load environment variables from .env file in current working directory.\n\n    &gt;&gt;&gt; load_dotenv()\n    \"\"\"\n    is_dotenv_used = dotenv.load_dotenv(dotenv.find_dotenv(usecwd=True))\n    logger.debug(f\"environment variables loaded from dotenv file: {is_dotenv_used}\")\n</code></pre>"},{"location":"reference/npc_io/#npc_io.testmod","title":"testmod","text":"<pre><code>testmod(**testmod_kwargs) -&gt; TestResults\n</code></pre> <p>Run doctests for the module, configured to ignore exception details and normalize whitespace.</p> <p>Accepts kwargs to pass to doctest.testmod().</p> <p>Add to modules to run doctests when run as a script: .. code-block:: text     if name == \"main\":         from npc_io import testmod         testmod()</p> Source code in <code>npc_io/__init__.py</code> <pre><code>def testmod(**testmod_kwargs) -&gt; doctest.TestResults:\n    \"\"\"\n    Run doctests for the module, configured to ignore exception details and\n    normalize whitespace.\n\n    Accepts kwargs to pass to doctest.testmod().\n\n    Add to modules to run doctests when run as a script:\n    .. code-block:: text\n        if __name__ == \"__main__\":\n            from npc_io import testmod\n            testmod()\n    \"\"\"\n    _ = testmod_kwargs.setdefault(\n        \"optionflags\", doctest.NORMALIZE_WHITESPACE | doctest.ELLIPSIS\n    )\n    return doctest.testmod(**testmod_kwargs)\n</code></pre>"},{"location":"reference/npc_io/cached_property/","title":"<code class=\"doc-symbol doc-symbol-nav doc-symbol-module\"></code> cached_property","text":""},{"location":"reference/npc_io/cached_property/#npc_io.cached_property","title":"cached_property","text":"<pre><code>cached_property(func: Callable[[Any], _T])\n</code></pre> <p>             Bases: <code>cached_property</code>, <code>Generic[_T]</code></p> <p>Copy of stdlib functools.cached_property minus faulty thread lock.</p> <p>Issue described here: https://github.com/python/cpython/issues/87634</p> <p>This version will make concurrent tasks across multiple instances faster, but each instance's cached properties will no longer be thread-safe - ie. don't dispatch the same instance to multiple threads without implementing your own lock.</p> <p>Examples: .. code-block:: text     &gt;&gt;&gt; import random     &gt;&gt;&gt; class Test:     ...     @cached_property     ...     def cached_prop(self):     ...         return random.random()     &gt;&gt;&gt; t = Test()     &gt;&gt;&gt; x = t.cached_prop     &gt;&gt;&gt; assert x == t.cached_prop</p> <pre><code># note: like the built-in property, cached_properties can be overwritten:\n&gt;&gt;&gt; t.cached_prop = 5\n&gt;&gt;&gt; assert t.cached_prop == 5\n</code></pre> Source code in <code>npc_io/cached_property.py</code> <pre><code>def __init__(self, func: Callable[[Any], _T]) -&gt; None:\n    super().__init__(func)\n</code></pre>"},{"location":"reference/npc_io/file_io/","title":"<code class=\"doc-symbol doc-symbol-nav doc-symbol-module\"></code> file_io","text":""},{"location":"reference/npc_io/file_io/#npc_io.file_io","title":"file_io","text":"<p>Tools for working with files on local machine, network or cloud.</p>"},{"location":"reference/npc_io/file_io/#npc_io.file_io.checksum","title":"checksum","text":"<pre><code>checksum(path: PathLike) -&gt; str\n</code></pre> <p>checksum('s3://codeocean-s3datasetsbucket-1u41qdg42ur9/4797cab2-9ea2-4747-8d15-5ba064837c1c/postprocessed/experiment1_Record Node 102#Neuropix-PXI-100.ProbeA-AP_recording1/template_metrics/params.json') '1C86AD2C'</p> Source code in <code>npc_io/file_io.py</code> <pre><code>def checksum(path: PathLike) -&gt; str:\n    \"\"\"\n    &gt;&gt;&gt; checksum('s3://codeocean-s3datasetsbucket-1u41qdg42ur9/4797cab2-9ea2-4747-8d15-5ba064837c1c/postprocessed/experiment1_Record Node 102#Neuropix-PXI-100.ProbeA-AP_recording1/template_metrics/params.json')\n    '1C86AD2C'\n    \"\"\"\n    path = from_pathlike(path)\n    hasher = crc32c.crc32c\n\n    def formatted(x) -&gt; str:\n        return f\"{x:08X}\"\n\n    blocks_per_chunk = 4096\n    multi_part_threshold_gb = 0.2\n    if file_size(path) &lt; multi_part_threshold_gb * 1024**3:\n        return formatted(hasher(path.read_bytes()))\n    hash = 0\n\n    with open(path, \"rb\") as f:\n        for chunk in iter(lambda: f.read(blocks_per_chunk), b\"\"):\n            hash = hasher(chunk, hash)\n    checksum = formatted(hash)\n    logger.debug(f\"{hasher} checksum of {path}: {checksum}\")\n    return checksum\n</code></pre>"},{"location":"reference/npc_io/file_io/#npc_io.file_io.checksums_match","title":"checksums_match","text":"<pre><code>checksums_match(*paths: PathLike) -&gt; bool\n</code></pre> <p>checksums_match(*['s3://codeocean-s3datasetsbucket-1u41qdg42ur9/4797cab2-9ea2-4747-8d15-5ba064837c1c/postprocessed/experiment1_Record Node 102#Neuropix-PXI-100.ProbeA-AP_recording1/template_metrics/params.json'] * 2) True</p> Source code in <code>npc_io/file_io.py</code> <pre><code>def checksums_match(*paths: PathLike) -&gt; bool:\n    \"\"\"\n    &gt;&gt;&gt; checksums_match(*['s3://codeocean-s3datasetsbucket-1u41qdg42ur9/4797cab2-9ea2-4747-8d15-5ba064837c1c/postprocessed/experiment1_Record Node 102#Neuropix-PXI-100.ProbeA-AP_recording1/template_metrics/params.json'] * 2)\n    True\n    \"\"\"\n    checksums = tuple(checksum(p) for p in paths)\n    return all(c == checksums[0] for c in checksums)\n</code></pre>"},{"location":"reference/npc_io/file_io/#npc_io.file_io.copy","title":"copy","text":"<pre><code>copy(\n    src: PathLike, dest: PathLike, max_attempts: int = 2\n) -&gt; None\n</code></pre> <p>Copy <code>src</code> to <code>dest</code> with checksum validation.</p> <ul> <li>copies recursively if <code>src</code> is a directory</li> <li>if dest already exists, checksums are compared, copying is skipped if they match</li> <li>attempts to copy up to 3 times if checksums don't match</li> <li>replaces existing symlinks with actual files</li> <li>creates parent dirs if needed</li> </ul> Source code in <code>npc_io/file_io.py</code> <pre><code>def copy(src: PathLike, dest: PathLike, max_attempts: int = 2) -&gt; None:\n    \"\"\"Copy `src` to `dest` with checksum validation.\n\n    - copies recursively if `src` is a directory\n    - if dest already exists, checksums are compared, copying is skipped if they match\n    - attempts to copy up to 3 times if checksums don't match\n    - replaces existing symlinks with actual files\n    - creates parent dirs if needed\n    \"\"\"\n    src, dest = from_pathlike(src), from_pathlike(dest)\n\n    if dest.exists() and dest.is_symlink():\n        dest.unlink()  # we'll replace symlink with src file\n\n    if src.is_dir():  # copy files recursively\n        for path in src.iterdir():\n            copy(path, dest / path.name)\n        return\n\n    if (\n        not dest.suffix\n    ):  # dest is a folder, but might not exist yet so can't use `is_dir`\n        dest = dest / src.name\n    dest.parent.mkdir(parents=True, exist_ok=True)\n\n    if not dest.exists():\n        shutil.copy2(src, dest)\n        logger.debug(f\"Copied {src} to {dest}\")\n\n    for _ in range(max_attempts):\n        if checksums_match(src, dest):\n            break\n        shutil.copy2(src, dest)\n    else:\n        raise OSError(\n            f\"Failed to copy {src} to {dest} with checksum-validation after {max_attempts} attempts\"\n        )\n    logger.debug(f\"Copy of {src} at {dest} validated with checksum\")\n</code></pre>"},{"location":"reference/npc_io/file_io/#npc_io.file_io.ctime","title":"ctime","text":"<pre><code>ctime(path: PathLike) -&gt; float\n</code></pre> <p>Return the creation time of a file in seconds since the epoch.</p> <p>ctime('s3://codeocean-s3datasetsbucket-1u41qdg42ur9/4797cab2-9ea2-4747-8d15-5ba064837c1c/postprocessed/experiment1_Record Node 102#Neuropix-PXI-100.ProbeA-AP_recording1/template_metrics/params.json') 1689287923.0 import datetime; datetime.datetime.fromtimestamp(_, datetime.timezone.utc) datetime.datetime(2023, 7, 13, 22, 38, 43, tzinfo=datetime.timezone.utc)</p> Source code in <code>npc_io/file_io.py</code> <pre><code>def ctime(path: PathLike) -&gt; float:\n    \"\"\"Return the creation time of a file in seconds since the epoch.\n\n    &gt;&gt;&gt; ctime('s3://codeocean-s3datasetsbucket-1u41qdg42ur9/4797cab2-9ea2-4747-8d15-5ba064837c1c/postprocessed/experiment1_Record Node 102#Neuropix-PXI-100.ProbeA-AP_recording1/template_metrics/params.json')\n    1689287923.0\n    &gt;&gt;&gt; import datetime; datetime.datetime.fromtimestamp(_, datetime.timezone.utc)\n    datetime.datetime(2023, 7, 13, 22, 38, 43, tzinfo=datetime.timezone.utc)\n    \"\"\"\n    path = from_pathlike(path)\n    with contextlib.suppress(AttributeError):\n        return path.stat().st_ctime\n    with contextlib.suppress(AttributeError):\n        return path.stat()[\"LastModified\"].timestamp()\n    raise RuntimeError(f\"Could not get size of {path}\")\n</code></pre>"},{"location":"reference/npc_io/file_io/#npc_io.file_io.dir_size","title":"dir_size","text":"<pre><code>dir_size(path: PathLike) -&gt; int\n</code></pre> <p>Return the size of a directory in bytes</p> Source code in <code>npc_io/file_io.py</code> <pre><code>def dir_size(path: PathLike) -&gt; int:\n    \"\"\"Return the size of a directory in bytes\"\"\"\n    path = from_pathlike(path)\n    if not path.is_dir():\n        raise ValueError(f\"{path} is not a directory\")\n    dir_size = 0\n    dir_size += sum(file_size(f) for f in path.rglob(\"*\") if f.is_file())\n    return dir_size\n</code></pre>"},{"location":"reference/npc_io/file_io/#npc_io.file_io.dir_size_gb","title":"dir_size_gb","text":"<pre><code>dir_size_gb(path: PathLike) -&gt; float\n</code></pre> <p>Return the size of a directory in GB</p> Source code in <code>npc_io/file_io.py</code> <pre><code>def dir_size_gb(path: PathLike) -&gt; float:\n    \"\"\"Return the size of a directory in GB\"\"\"\n    return round(dir_size(path) / 1024**3, 1)\n</code></pre>"},{"location":"reference/npc_io/file_io/#npc_io.file_io.free_gb","title":"free_gb","text":"<pre><code>free_gb(path: PathLike) -&gt; float\n</code></pre> <p>Return free space at <code>path</code>, to .1 GB. Raises FileNotFoundError if <code>path</code> not accessible.</p> Source code in <code>npc_io/file_io.py</code> <pre><code>def free_gb(path: PathLike) -&gt; float:\n    \"Return free space at `path`, to .1 GB. Raises FileNotFoundError if `path` not accessible.\"\n    path = from_pathlike(path)\n    return round(shutil.disk_usage(path).free / 1024**3, 1)\n</code></pre>"},{"location":"reference/npc_io/file_io/#npc_io.file_io.from_pathlike","title":"from_pathlike","text":"<pre><code>from_pathlike(pathlike: PathLike) -&gt; UPath\n</code></pre> <p>from_pathlike('s3://aind-data-bucket/experiment2_Record Node 102#probeA.png') S3Path('s3://aind-data-bucket/experiment2_Record Node 102#probeA.png')</p> <p>from_pathlike('s3://codeocean-s3datasetsbucket-1u41qdg42ur9/4797cab2-9ea2-4747-8d15-5ba064837c1c/postprocessed/experiment1_Record Node 102#Neuropix-PXI-100.ProbeA-AP_recording1/template_metrics/params.json') S3Path('s3://codeocean-s3datasetsbucket-1u41qdg42ur9/4797cab2-9ea2-4747-8d15-5ba064837c1c/postprocessed/experiment1_Record Node 102#Neuropix-PXI-100.ProbeA-AP_recording1/template_metrics/params.json')</p> Source code in <code>npc_io/file_io.py</code> <pre><code>def from_pathlike(pathlike: PathLike) -&gt; upath.UPath:\n    \"\"\"\n    &gt;&gt;&gt; from_pathlike('s3://aind-data-bucket/experiment2_Record Node 102#probeA.png')\n    S3Path('s3://aind-data-bucket/experiment2_Record Node 102#probeA.png')\n\n    &gt;&gt;&gt; from_pathlike('s3://codeocean-s3datasetsbucket-1u41qdg42ur9/4797cab2-9ea2-4747-8d15-5ba064837c1c/postprocessed/experiment1_Record Node 102#Neuropix-PXI-100.ProbeA-AP_recording1/template_metrics/params.json')\n    S3Path('s3://codeocean-s3datasetsbucket-1u41qdg42ur9/4797cab2-9ea2-4747-8d15-5ba064837c1c/postprocessed/experiment1_Record Node 102#Neuropix-PXI-100.ProbeA-AP_recording1/template_metrics/params.json')\n    \"\"\"\n    if isinstance(pathlike, upath.UPath):\n        return pathlike\n    path: str = os.fsdecode(pathlike)\n    # UPath will do rsplit('#')[0] on path\n    if \"#\" in (p := pathlib.Path(path)).name:\n        return upath.UPath(path).with_name(p.name)\n    if \"#\" in p.parent.as_posix():\n        if p.parent.as_posix().count(\"#\") &gt; 1:\n            raise ValueError(\n                f\"Path {p} contains multiple '#' in a parent dirs, which we don't have a fix for yet\"\n            )\n        for parent in p.parents:\n            if \"#\" in parent.name:\n                # we can't create or join the problematic `#`, so we have to 'discover' it\n                new = upath.UPath(path).with_name(parent.name)\n                for part in p.relative_to(parent).parts:\n                    result = next(\n                        new.glob(part),\n                        None,\n                    )  # we can't create or join the problem-#, so we have to 'discover' it\n                    if result is None:\n                        raise FileNotFoundError(\n                            f\"In attempting to handle a path containing '#', we couldn't find {path}\"\n                        )\n                    new = result\n                return new\n    return upath.UPath(path)\n</code></pre>"},{"location":"reference/npc_io/file_io/#npc_io.file_io.move","title":"move","text":"<pre><code>move(\n    src: PathLike, dest: PathLike, **rmtree_kwargs\n) -&gt; None\n</code></pre> <p>Copy <code>src</code> to <code>dest</code> with checksum validation, then delete <code>src</code>.</p> Source code in <code>npc_io/file_io.py</code> <pre><code>def move(src: PathLike, dest: PathLike, **rmtree_kwargs) -&gt; None:\n    \"\"\"Copy `src` to `dest` with checksum validation, then delete `src`.\"\"\"\n    src, dest = from_pathlike(src), from_pathlike(dest)\n    copy(src, dest)\n    if src.is_dir():\n        shutil.rmtree(src, **rmtree_kwargs)\n    else:\n        src.unlink()\n    logger.debug(f\"Deleted {src}\")\n</code></pre>"},{"location":"reference/npc_io/file_io/#npc_io.file_io.run_and_save_notebook","title":"run_and_save_notebook","text":"<pre><code>run_and_save_notebook(\n    notebook_path: PathLike,\n    save_path: PathLike,\n    env: dict[str, Any] | None = None,\n    format: Literal[\n        \"markdown\", \"notebook\", \"script\", \"html\", \"pdf\"\n    ] = \"notebook\",\n) -&gt; UPath\n</code></pre> <p>Use jupyter nbconvert to run a specific notebook file in a subprocess, saving the output to a new file.</p> <ul> <li>to pass parameters to the notebook, pass them here with the <code>env</code> dict, and load   them from the <code>os.environ</code> dict in the notebook</li> <li><code>format</code> can be specified - available options are here:   https://nbconvert.readthedocs.io/en/latest/usage.html#supported-output-formats</li> </ul> Source code in <code>npc_io/file_io.py</code> <pre><code>def run_and_save_notebook(\n    notebook_path: PathLike,\n    save_path: PathLike,\n    env: dict[str, Any] | None = None,\n    format: Literal[\"markdown\", \"notebook\", \"script\", \"html\", \"pdf\"] = \"notebook\",\n) -&gt; upath.UPath:\n    \"\"\"Use jupyter nbconvert to run a specific notebook file in a subprocess,\n    saving the output to a new file.\n\n    - to pass parameters to the notebook, pass them here with the `env` dict, and load\n      them from the `os.environ` dict in the notebook\n    - `format` can be specified - available options are here:\n      https://nbconvert.readthedocs.io/en/latest/usage.html#supported-output-formats\n    \"\"\"\n    notebook_path = from_pathlike(notebook_path)\n    assert (notebook_path).exists()\n    save_path = from_pathlike(save_path)\n    if save_path.is_dir():\n        save_path.mkdir(exist_ok=True, parents=True)\n        save_path = save_path / notebook_path.name\n\n    subprocess.run(  # pragma: no cover\n        f\"jupyter nbconvert --to {format} --execute --allow-errors --output {save_path.as_posix()}  {notebook_path.as_posix()}\",\n        check=True,\n        shell=True,\n        capture_output=False,\n        env=env,\n    )  # pragma: no cover\n    return save_path\n</code></pre>"},{"location":"reference/npc_io/file_io/#npc_io.file_io.size","title":"size","text":"<pre><code>size(path: PathLike) -&gt; int\n</code></pre> <p>Return the size of a file or directory in bytes.</p> <p>size('s3://codeocean-s3datasetsbucket-1u41qdg42ur9/4797cab2-9ea2-4747-8d15-5ba064837c1c/postprocessed/experiment1_Record Node 102#Neuropix-PXI-100.ProbeA-AP_recording1/template_metrics/params.json') 268</p> Source code in <code>npc_io/file_io.py</code> <pre><code>def size(path: PathLike) -&gt; int:\n    \"\"\"Return the size of a file or directory in bytes.\n\n    &gt;&gt;&gt; size('s3://codeocean-s3datasetsbucket-1u41qdg42ur9/4797cab2-9ea2-4747-8d15-5ba064837c1c/postprocessed/experiment1_Record Node 102#Neuropix-PXI-100.ProbeA-AP_recording1/template_metrics/params.json')\n    268\n    \"\"\"\n    path = from_pathlike(path)\n    return dir_size(path) if path.is_dir() else file_size(path)\n</code></pre>"},{"location":"reference/npc_io/file_io/#npc_io.file_io.size_gb","title":"size_gb","text":"<pre><code>size_gb(path: PathLike) -&gt; float\n</code></pre> <p>Return the size of a file or directory in GB.</p> <p>size_gb('s3://codeocean-s3datasetsbucket-1u41qdg42ur9/4797cab2-9ea2-4747-8d15-5ba064837c1c/postprocessed/experiment1_Record Node 102#Neuropix-PXI-100.ProbeA-AP_recording1') 1.7</p> Source code in <code>npc_io/file_io.py</code> <pre><code>def size_gb(path: PathLike) -&gt; float:\n    \"\"\"Return the size of a file or directory in GB.\n\n    &gt;&gt;&gt; size_gb('s3://codeocean-s3datasetsbucket-1u41qdg42ur9/4797cab2-9ea2-4747-8d15-5ba064837c1c/postprocessed/experiment1_Record Node 102#Neuropix-PXI-100.ProbeA-AP_recording1')\n    1.7\n    \"\"\"\n    return round(size(path) / 1024**3, 1)\n</code></pre>"},{"location":"reference/npc_io/file_io/#npc_io.file_io.symlink","title":"symlink","text":"<pre><code>symlink(src: PathLike, dest: PathLike) -&gt; None\n</code></pre> <p>Create symlink at <code>dest</code> pointing to file at <code>src</code>.</p> <ul> <li>creates symlinks recursively if <code>src</code> is a directory</li> <li>creates parent dirs if needed (as folders, not symlinks)</li> <li>skips if symlink already exists and points to <code>src</code></li> <li>replaces existing file or symlink pointing to a different location</li> </ul> Source code in <code>npc_io/file_io.py</code> <pre><code>def symlink(src: PathLike, dest: PathLike) -&gt; None:\n    \"\"\"Create symlink at `dest` pointing to file at `src`.\n\n    - creates symlinks recursively if `src` is a directory\n    - creates parent dirs if needed (as folders, not symlinks)\n    - skips if symlink already exists and points to `src`\n    - replaces existing file or symlink pointing to a different location\n    \"\"\"\n    src, dest = from_pathlike(src), from_pathlike(dest)\n    if src.is_dir():\n        for path in src.iterdir():\n            symlink(src, dest / path.name)\n    dest.parent.mkdir(parents=True, exist_ok=True)\n    if dest.is_symlink() and dest.resolve() == src.resolve():\n        logger.debug(f\"Symlink already exists to {src} from {dest}\")\n        return\n    with contextlib.suppress(FileNotFoundError):\n        dest.unlink()\n    with contextlib.suppress(FileExistsError):\n        dest.symlink_to(src)\n    logger.debug(f\"Created symlink to {src} from {dest}\")\n</code></pre>"},{"location":"reference/npc_io/lazy_dict/","title":"<code class=\"doc-symbol doc-symbol-nav doc-symbol-module\"></code> lazy_dict","text":""},{"location":"reference/npc_io/lazy_dict/#npc_io.lazy_dict","title":"lazy_dict","text":"<p>Mapping class for postponed evaluation of functions and caching of results.</p>"},{"location":"reference/npc_io/lazy_dict/#npc_io.lazy_dict.LazyDict","title":"LazyDict","text":"<pre><code>LazyDict(*args, **kwargs)\n</code></pre> <p>             Bases: <code>Mapping[K, V]</code></p> <p>Dict for postponed evaluation of functions and caching of results.</p> <p>Assign values as a tuple of (callable, args, kwargs). The callable will be evaluated when the key is first accessed. The result will be cached and returned directly on subsequent access.</p> <p>Effectively immutable after initialization.</p> <p>Examples: .. code-block:: text     # input values in the form <code>tuple(callable, args: Sequence, kwargs: Mapping)</code>     &gt;&gt;&gt; import random     &gt;&gt;&gt; callable, args, kwargs = random.choice, (range(100),), {}</p> <pre><code># initialize with keyword arguments, like the built-in dict:\n&gt;&gt;&gt; d = LazyDict(choice=(callable, args, kwargs))\n\n# or with a dict:\n&gt;&gt;&gt; d = LazyDict({'choice': (callable, args, kwargs)})\n\n&gt;&gt;&gt; d\nLazyDict(keys=['choice'])\n\n# values are only computed the first time they're accessed, then cached:\n&gt;&gt;&gt; c = d['choice']\n&gt;&gt;&gt; c                               # doctest: +SKIP\n5\n&gt;&gt;&gt; c == d['choice']\nTrue\n\n\n# other immutable dict-like behavior:\n&gt;&gt;&gt; len(d)\n1\n&gt;&gt;&gt; [k for k in d]\n['choice']\n&gt;&gt;&gt; d.get('random') is None\nTrue\n</code></pre> Source code in <code>npc_io/lazy_dict.py</code> <pre><code>def __init__(self, *args, **kwargs) -&gt; None:\n    self._raw_dict = dict(*args, **kwargs)\n</code></pre>"},{"location":"reference/npc_io/types/","title":"<code class=\"doc-symbol doc-symbol-nav doc-symbol-module\"></code> types","text":""},{"location":"reference/npc_io/types/#npc_io.types","title":"types","text":"<p>Type aliases and other typing-related definitions.</p>"},{"location":"coverage/","title":"Coverage report","text":""}]}